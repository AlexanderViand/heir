---
title: Fold Convert Layout into Assign Layout
weight: 32
---

## Overview

The fold-convert-layout-into-assign-layout pass merges
`tensor_ext.convert_layout` operations into preceding `tensor_ext.assign_layout`
operations. This optimization eliminates unnecessary layout conversions by
directly encoding cleartexts into the target layout, rather than encoding and
then converting.

## Input/Output

- **Input**: IR with `tensor_ext.assign_layout` operations followed by
  `tensor_ext.convert_layout` operations
- **Output**: Optimized IR where layout conversions are folded into the initial
  layout assignments

## Options

This pass has no command-line options.

## Usage Examples

```bash
heir-opt --fold-convert-layout-into-assign-layout input.mlir
```

Typically used in layout optimization pipelines:

```bash
heir-opt --layout-propagation --fold-convert-layout-into-assign-layout --canonicalize input.mlir
```

## When to Use

Use this pass when you have:

1. `tensor_ext.assign_layout` operations immediately followed by
   `tensor_ext.convert_layout`
1. IR where layout assignments can be optimized by avoiding intermediate
   conversions
1. Compilation pipelines that benefit from minimized layout conversion overhead
1. Code generated by layout propagation that creates suboptimal conversion
   patterns

Typical placement in compilation pipelines:

1. After `layout-propagation` which may create assign/convert pairs
1. Before more complex layout optimization passes
1. Early in the optimization pipeline to simplify subsequent passes
1. Often followed by canonicalization to clean up the result

## How It Works

The pass performs pattern matching and folding:

1. **Pattern Recognition**: Identifies `assign_layout` ops followed by
   `convert_layout` ops
1. **Single Consumer**: Handles cases where assign_layout has one convert_layout
   user
1. **Multiple Consumers**: Creates multiple assign_layout ops for multiple
   convert_layout users
1. **Direct Encoding**: Replaces the assign/convert pair with direct assignment
   to target layout

## Example

**Before optimization:**

```mlir
func.func @example(%cleartext: tensor<32xi16>) -> tensor<32xi16> {
  %0 = tensor_ext.assign_layout %cleartext {tensor_ext.layout = #initial_layout} : tensor<32xi16>
  %1 = tensor_ext.convert_layout %0 {
    from_layout = #initial_layout,
    to_layout = #target_layout
  } : tensor<32xi16>
  return %1 : tensor<32xi16>
}
```

**After optimization:**

```mlir
func.func @example(%cleartext: tensor<32xi16>) -> tensor<32xi16> {
  %0 = tensor_ext.assign_layout %cleartext {tensor_ext.layout = #target_layout} : tensor<32xi16>
  return %0 : tensor<32xi16>
}
```

**Multiple consumers case - Before:**

```mlir
func.func @multiple_users(%cleartext: tensor<32xi16>) -> (tensor<32xi16>, tensor<32xi16>) {
  %0 = tensor_ext.assign_layout %cleartext {tensor_ext.layout = #initial_layout} : tensor<32xi16>
  %1 = tensor_ext.convert_layout %0 {
    from_layout = #initial_layout,
    to_layout = #layout1
  } : tensor<32xi16>
  %2 = tensor_ext.convert_layout %0 {
    from_layout = #initial_layout,
    to_layout = #layout2
  } : tensor<32xi16>
  return %1, %2 : tensor<32xi16>, tensor<32xi16>
}
```

**Multiple consumers case - After:**

```mlir
func.func @multiple_users(%cleartext: tensor<32xi16>) -> (tensor<32xi16>, tensor<32xi16>) {
  %0 = tensor_ext.assign_layout %cleartext {tensor_ext.layout = #layout1} : tensor<32xi16>
  %1 = tensor_ext.assign_layout %cleartext {tensor_ext.layout = #layout2} : tensor<32xi16>
  return %0, %1 : tensor<32xi16>, tensor<32xi16>
}
```

## Benefits

- **Reduced Conversions**: Eliminates unnecessary layout conversion operations
- **Direct Encoding**: Encodes cleartext directly into target layout
- **Improved Efficiency**: Reduces computational overhead of layout
  transformations
- **Cleaner IR**: Simplifies the intermediate representation

## Use Cases

This optimization is particularly beneficial for:

1. **Plaintext Packing**: When cleartexts need to be encoded into specific
   ciphertext layouts
1. **Layout Propagation Cleanup**: Removing artifacts from layout analysis
   passes
1. **Encoding Optimization**: Minimizing the cost of plaintext-to-ciphertext
   transitions
1. **Pipeline Efficiency**: Reducing unnecessary operations in compilation
   pipelines

## Limitations

- Only works with direct assign_layout/convert_layout patterns
- Requires that the convert_layout operation immediately follows assign_layout
- Does not optimize more complex layout conversion chains
- Limited to tensor_ext dialect operations

## Related Passes

- Works well after `layout-propagation` which creates assign_layout operations
- Can be combined with `layout-optimization` for comprehensive layout
  optimization
- Often used with canonicalization passes to clean up the result
- May be followed by other tensor_ext optimization passes
